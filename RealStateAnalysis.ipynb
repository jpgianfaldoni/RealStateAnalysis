{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(url, file_name):\n",
    "    \n",
    "    print(\"Getting page url\")\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    driver.set_page_load_timeout(60)\n",
    "    driver.get(url)\n",
    "    \n",
    "    WebDriverWait(driver, 20).until(EC.visibility_of_element_located((By.CLASS_NAME, \"sc-ftvSup.xPMpo\")))\n",
    "    \n",
    "    print(\"Loading more information\")\n",
    "\n",
    "       \n",
    "    print(\"Collecting data\")\n",
    "    enderecos = []\n",
    "    regioes = []\n",
    "    tipos_valores = []\n",
    "    outras_informacoes = []\n",
    "    for i in range(20):\n",
    "        enderecos.append([x.text for x in driver.find_elements(By.CSS_SELECTOR, 'span[data-testid=\"house-card-address\"]')])\n",
    "        regioes.append([x.text for x in driver.find_elements(By.CSS_SELECTOR, 'span[data-testid=\"house-card-region\"]')])\n",
    "        tipos_valores.append([x.text for x in  driver.find_elements(By.CLASS_NAME, 'sc-gsnTZi.iRsaMY.sc-crXcEl.jddosl.CozyTypography')])\n",
    "        outras_informacoes.append(driver.find_elements(By.CSS_SELECTOR, 'small[data-testid=\"house-card-area\"]'))\n",
    "        WebDriverWait(driver, 20).until(EC.visibility_of_element_located((By.CLASS_NAME, \"sc-ftvSup.xPMpo\")))\n",
    "        elem = driver.find_elements(By.CLASS_NAME, \"sc-ftvSup.xPMpo\")\n",
    "        elem[0].click()\n",
    "        time.sleep(1)\n",
    "        print(i)\n",
    "\n",
    "\n",
    "    outras_informacoes_clean = []\n",
    "    for i in outras_informacoes:\n",
    "        for j in i:\n",
    "            outras_informacoes_clean.append(j.text)\n",
    "\n",
    "    enderecos = [item for sublist in enderecos for item in sublist]\n",
    "    regioes = [item for sublist in regioes for item in sublist]\n",
    "    tipos_valores = [item for sublist in tipos_valores for item in sublist]\n",
    "\n",
    "    tipo = []\n",
    "    valores = []\n",
    "\n",
    "    for i in range(len(tipos_valores)):\n",
    "        if tipos_valores[i].startswith(\"R$\"):\n",
    "            valores.append(tipos_valores[i])\n",
    "        else:\n",
    "            tipo.append(tipos_valores[i])\n",
    "    metragem = []\n",
    "    n_quartos = []\n",
    "    n_vagas = []\n",
    "    for info in outras_informacoes_clean:\n",
    "        splited_info  = info.split('•')\n",
    "        metragem.append(int(splited_info[0].strip('m² ')))\n",
    "        n_quartos.append(int(splited_info[1].strip(\" quartos \")))\n",
    "        n_vagas.append(int((splited_info[2].strip(\" vagas \"))))\n",
    "    valores = [item.strip(\"R$ \").replace(\".\",\"\")  for item in valores]\n",
    "    regioes = [item.strip(\"R$ \").replace(\".\",\"\") for item in regioes]\n",
    "    \n",
    "    print(\"Building the dataset\")\n",
    "\n",
    "    real_state = {\"tipo\": tipo, \"enderecos\" : enderecos, \"regioes\" :  regioes, \"valores\" : valores, \"metragem\" : metragem, \"n_quartos\" : n_quartos, \"n_vagas\" : n_vagas}\n",
    "    df = pd.DataFrame(real_state)\n",
    "    df.to_csv(file_name, index=False)\n",
    "    \n",
    "    print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regioes = [\"vila-olimpia\", \"jardim-paulista\", \"jardim-europa\"]\n",
    "for regiao in regioes:\n",
    "    file_name= f\"real_state_{regiao}.csv\"\n",
    "    if not os.path.exists(file_name):\n",
    "        get_dataset(f'https://www.quintoandar.com.br/comprar/imovel/{regiao}-sao-paulo-sp-brasil', file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pinheiros = pd.read_csv(\"real_state_pinheiros.csv\")\n",
    "df_jardim_paulista = pd.read_csv(\"real_state_jardim-paulista.csv\")\n",
    "df_jardim_europa = pd.read_csv(\"real_state_jardim-europa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_pinheiros, df_jardim_paulista, df_jardim_europa], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"enderecos\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "transformed = ohe.fit_transform(df[['tipo']])\n",
    "df = df.drop(columns=['tipo'])\n",
    "df[ohe.categories_[0]] = transformed.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "transformed_2 = ohe.fit_transform(df[['regioes']])\n",
    "df = df.drop(columns=['regioes'])\n",
    "df[ohe.categories_[0]] = transformed_2.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"valores\"])\n",
    "y = df.valores\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression = LinearRegression()\n",
    "\n",
    "linear_regression.fit(X_train, y_train)\n",
    "\n",
    "y_pred = linear_regression.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared Score: 0.6724248017032823\n"
     ]
    }
   ],
   "source": [
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"R-squared Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared Score: 0.8489202812334167\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=10, random_state=10)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"R-squared Score:\", r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
